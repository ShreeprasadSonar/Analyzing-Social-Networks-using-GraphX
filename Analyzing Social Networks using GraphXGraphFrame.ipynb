{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZRv9_5UYXBk"
      },
      "source": [
        "Dataset: https://snap.stanford.edu/data/soc-Epinions1.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFMJjhtrVDzR"
      },
      "outputs": [],
      "source": [
        "!rm -rf spark-3.1.1-bin-hadoop3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmuxvaDfVFMr"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install -q findspark pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8rnPcn5Va34"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOYa5wijVh4o",
        "outputId": "c8e8cd4c-50ac-42e3-bfa9-159e33e60f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TMot71PVibw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f77348b-fd6e-4a98-f1aa-19437b390643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyspark\n",
            "Version: 3.5.0\n",
            "Summary: Apache Spark Python API\n",
            "Home-page: https://github.com/apache/spark/tree/master/python\n",
            "Author: Spark Developers\n",
            "Author-email: dev@spark.apache.org\n",
            "License: http://www.apache.org/licenses/LICENSE-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: py4j\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQnIKF0Vjqg",
        "outputId": "feac501b-fc7c-4c89-a0ae-9969679f42e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.23.5)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJylg7onVk9f",
        "outputId": "3ad22e2a-16ef-4b23-b420-8b212fe805cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g04QpAkwVmN2",
        "outputId": "e25befbb-ae47-4a02-9d11-e74b1158484e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  242k  100  242k    0     0  1008k      0 --:--:-- --:--:-- --:--:-- 1008k\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o \"/usr/local/lib/python3.10/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.3.2-s_2.11.jar\" https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.1-s_2.12/graphframes-0.8.2-spark3.1-s_2.12.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPl75rg4Vnoq",
        "outputId": "996f62a0-72c5-4f8d-db7c-820b2cfbc1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation-1.1.1.jar\n",
            "aircompressor-0.25.jar\n",
            "algebra_2.12-2.0.1.jar\n",
            "annotations-17.0.0.jar\n",
            "antlr4-runtime-4.9.3.jar\n",
            "antlr-runtime-3.5.2.jar\n",
            "aopalliance-repackaged-2.6.1.jar\n",
            "arpack-3.0.3.jar\n",
            "arpack_combined_all-0.1.jar\n",
            "arrow-format-12.0.1.jar\n",
            "arrow-memory-core-12.0.1.jar\n",
            "arrow-memory-netty-12.0.1.jar\n",
            "arrow-vector-12.0.1.jar\n",
            "audience-annotations-0.5.0.jar\n",
            "avro-1.11.2.jar\n",
            "avro-ipc-1.11.2.jar\n",
            "avro-mapred-1.11.2.jar\n",
            "blas-3.0.3.jar\n",
            "bonecp-0.8.0.RELEASE.jar\n",
            "breeze_2.12-2.1.0.jar\n",
            "breeze-macros_2.12-2.1.0.jar\n",
            "cats-kernel_2.12-2.1.1.jar\n",
            "chill_2.12-0.10.0.jar\n",
            "chill-java-0.10.0.jar\n",
            "commons-cli-1.5.0.jar\n",
            "commons-codec-1.16.0.jar\n",
            "commons-collections-3.2.2.jar\n",
            "commons-collections4-4.4.jar\n",
            "commons-compiler-3.1.9.jar\n",
            "commons-compress-1.23.0.jar\n",
            "commons-crypto-1.1.0.jar\n",
            "commons-dbcp-1.4.jar\n",
            "commons-io-2.13.0.jar\n",
            "commons-lang-2.6.jar\n",
            "commons-lang3-3.12.0.jar\n",
            "commons-logging-1.1.3.jar\n",
            "commons-math3-3.6.1.jar\n",
            "commons-pool-1.5.4.jar\n",
            "commons-text-1.10.0.jar\n",
            "compress-lzf-1.1.2.jar\n",
            "curator-client-2.13.0.jar\n",
            "curator-framework-2.13.0.jar\n",
            "curator-recipes-2.13.0.jar\n",
            "datanucleus-api-jdo-4.2.4.jar\n",
            "datanucleus-core-4.1.17.jar\n",
            "datanucleus-rdbms-4.1.19.jar\n",
            "datasketches-java-3.3.0.jar\n",
            "datasketches-memory-2.1.0.jar\n",
            "derby-10.14.2.0.jar\n",
            "dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "flatbuffers-java-1.12.0.jar\n",
            "graphframes-0.8.2-spark3.3.2-s_2.11.jar\n",
            "gson-2.2.4.jar\n",
            "guava-14.0.1.jar\n",
            "hadoop-client-api-3.3.4.jar\n",
            "hadoop-client-runtime-3.3.4.jar\n",
            "hadoop-shaded-guava-1.1.1.jar\n",
            "hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "HikariCP-2.5.1.jar\n",
            "hive-beeline-2.3.9.jar\n",
            "hive-cli-2.3.9.jar\n",
            "hive-common-2.3.9.jar\n",
            "hive-exec-2.3.9-core.jar\n",
            "hive-jdbc-2.3.9.jar\n",
            "hive-llap-common-2.3.9.jar\n",
            "hive-metastore-2.3.9.jar\n",
            "hive-serde-2.3.9.jar\n",
            "hive-service-rpc-3.1.3.jar\n",
            "hive-shims-0.23-2.3.9.jar\n",
            "hive-shims-2.3.9.jar\n",
            "hive-shims-common-2.3.9.jar\n",
            "hive-shims-scheduler-2.3.9.jar\n",
            "hive-storage-api-2.8.1.jar\n",
            "hk2-api-2.6.1.jar\n",
            "hk2-locator-2.6.1.jar\n",
            "hk2-utils-2.6.1.jar\n",
            "httpclient-4.5.14.jar\n",
            "httpcore-4.4.16.jar\n",
            "istack-commons-runtime-3.0.8.jar\n",
            "ivy-2.5.1.jar\n",
            "jackson-annotations-2.15.2.jar\n",
            "jackson-core-2.15.2.jar\n",
            "jackson-core-asl-1.9.13.jar\n",
            "jackson-databind-2.15.2.jar\n",
            "jackson-dataformat-yaml-2.15.2.jar\n",
            "jackson-datatype-jsr310-2.15.2.jar\n",
            "jackson-mapper-asl-1.9.13.jar\n",
            "jackson-module-scala_2.12-2.15.2.jar\n",
            "jakarta.annotation-api-1.3.5.jar\n",
            "jakarta.inject-2.6.1.jar\n",
            "jakarta.servlet-api-4.0.3.jar\n",
            "jakarta.validation-api-2.0.2.jar\n",
            "jakarta.ws.rs-api-2.1.6.jar\n",
            "jakarta.xml.bind-api-2.3.2.jar\n",
            "janino-3.1.9.jar\n",
            "javassist-3.29.2-GA.jar\n",
            "javax.jdo-3.2.0-m3.jar\n",
            "javolution-5.5.1.jar\n",
            "jaxb-runtime-2.3.2.jar\n",
            "jcl-over-slf4j-2.0.7.jar\n",
            "jdo-api-3.0.1.jar\n",
            "jersey-client-2.40.jar\n",
            "jersey-common-2.40.jar\n",
            "jersey-container-servlet-2.40.jar\n",
            "jersey-container-servlet-core-2.40.jar\n",
            "jersey-hk2-2.40.jar\n",
            "jersey-server-2.40.jar\n",
            "JLargeArrays-1.5.jar\n",
            "jline-2.14.6.jar\n",
            "joda-time-2.12.5.jar\n",
            "jodd-core-3.5.2.jar\n",
            "jpam-1.1.jar\n",
            "json-1.8.jar\n",
            "json4s-ast_2.12-3.7.0-M11.jar\n",
            "json4s-core_2.12-3.7.0-M11.jar\n",
            "json4s-jackson_2.12-3.7.0-M11.jar\n",
            "json4s-scalap_2.12-3.7.0-M11.jar\n",
            "jsr305-3.0.0.jar\n",
            "jta-1.1.jar\n",
            "JTransforms-3.1.jar\n",
            "jul-to-slf4j-2.0.7.jar\n",
            "kryo-shaded-4.0.2.jar\n",
            "kubernetes-client-6.7.2.jar\n",
            "kubernetes-client-api-6.7.2.jar\n",
            "kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "kubernetes-model-admissionregistration-6.7.2.jar\n",
            "kubernetes-model-apiextensions-6.7.2.jar\n",
            "kubernetes-model-apps-6.7.2.jar\n",
            "kubernetes-model-autoscaling-6.7.2.jar\n",
            "kubernetes-model-batch-6.7.2.jar\n",
            "kubernetes-model-certificates-6.7.2.jar\n",
            "kubernetes-model-common-6.7.2.jar\n",
            "kubernetes-model-coordination-6.7.2.jar\n",
            "kubernetes-model-core-6.7.2.jar\n",
            "kubernetes-model-discovery-6.7.2.jar\n",
            "kubernetes-model-events-6.7.2.jar\n",
            "kubernetes-model-extensions-6.7.2.jar\n",
            "kubernetes-model-flowcontrol-6.7.2.jar\n",
            "kubernetes-model-gatewayapi-6.7.2.jar\n",
            "kubernetes-model-metrics-6.7.2.jar\n",
            "kubernetes-model-networking-6.7.2.jar\n",
            "kubernetes-model-node-6.7.2.jar\n",
            "kubernetes-model-policy-6.7.2.jar\n",
            "kubernetes-model-rbac-6.7.2.jar\n",
            "kubernetes-model-resource-6.7.2.jar\n",
            "kubernetes-model-scheduling-6.7.2.jar\n",
            "kubernetes-model-storageclass-6.7.2.jar\n",
            "lapack-3.0.3.jar\n",
            "leveldbjni-all-1.8.jar\n",
            "libfb303-0.9.3.jar\n",
            "libthrift-0.12.0.jar\n",
            "log4j-1.2-api-2.20.0.jar\n",
            "log4j-api-2.20.0.jar\n",
            "log4j-core-2.20.0.jar\n",
            "log4j-slf4j2-impl-2.20.0.jar\n",
            "logging-interceptor-3.12.12.jar\n",
            "lz4-java-1.8.0.jar\n",
            "mesos-1.4.3-shaded-protobuf.jar\n",
            "metrics-core-4.2.19.jar\n",
            "metrics-graphite-4.2.19.jar\n",
            "metrics-jmx-4.2.19.jar\n",
            "metrics-json-4.2.19.jar\n",
            "metrics-jvm-4.2.19.jar\n",
            "minlog-1.3.0.jar\n",
            "netty-all-4.1.96.Final.jar\n",
            "netty-buffer-4.1.96.Final.jar\n",
            "netty-codec-4.1.96.Final.jar\n",
            "netty-codec-http2-4.1.96.Final.jar\n",
            "netty-codec-http-4.1.96.Final.jar\n",
            "netty-codec-socks-4.1.96.Final.jar\n",
            "netty-common-4.1.96.Final.jar\n",
            "netty-handler-4.1.96.Final.jar\n",
            "netty-handler-proxy-4.1.96.Final.jar\n",
            "netty-resolver-4.1.96.Final.jar\n",
            "netty-transport-4.1.96.Final.jar\n",
            "netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "objenesis-3.3.jar\n",
            "okhttp-3.12.12.jar\n",
            "okio-1.15.0.jar\n",
            "opencsv-2.3.jar\n",
            "orc-core-1.9.1-shaded-protobuf.jar\n",
            "orc-mapreduce-1.9.1-shaded-protobuf.jar\n",
            "orc-shims-1.9.1.jar\n",
            "oro-2.0.8.jar\n",
            "osgi-resource-locator-1.0.3.jar\n",
            "paranamer-2.8.jar\n",
            "parquet-column-1.13.1.jar\n",
            "parquet-common-1.13.1.jar\n",
            "parquet-encoding-1.13.1.jar\n",
            "parquet-format-structures-1.13.1.jar\n",
            "parquet-hadoop-1.13.1.jar\n",
            "parquet-jackson-1.13.1.jar\n",
            "pickle-1.3.jar\n",
            "py4j-0.10.9.7.jar\n",
            "RoaringBitmap-0.9.45.jar\n",
            "rocksdbjni-8.3.2.jar\n",
            "scala-collection-compat_2.12-2.7.0.jar\n",
            "scala-compiler-2.12.18.jar\n",
            "scala-library-2.12.18.jar\n",
            "scala-parser-combinators_2.12-2.3.0.jar\n",
            "scala-reflect-2.12.18.jar\n",
            "scala-xml_2.12-2.1.0.jar\n",
            "shims-0.9.45.jar\n",
            "slf4j-api-2.0.7.jar\n",
            "snakeyaml-2.0.jar\n",
            "snakeyaml-engine-2.6.jar\n",
            "snappy-java-1.1.10.3.jar\n",
            "spark-catalyst_2.12-3.5.0.jar\n",
            "spark-common-utils_2.12-3.5.0.jar\n",
            "spark-core_2.12-3.5.0.jar\n",
            "spark-graphx_2.12-3.5.0.jar\n",
            "spark-hive_2.12-3.5.0.jar\n",
            "spark-hive-thriftserver_2.12-3.5.0.jar\n",
            "spark-kubernetes_2.12-3.5.0.jar\n",
            "spark-kvstore_2.12-3.5.0.jar\n",
            "spark-launcher_2.12-3.5.0.jar\n",
            "spark-mesos_2.12-3.5.0.jar\n",
            "spark-mllib_2.12-3.5.0.jar\n",
            "spark-mllib-local_2.12-3.5.0.jar\n",
            "spark-network-common_2.12-3.5.0.jar\n",
            "spark-network-shuffle_2.12-3.5.0.jar\n",
            "spark-repl_2.12-3.5.0.jar\n",
            "spark-sketch_2.12-3.5.0.jar\n",
            "spark-sql_2.12-3.5.0.jar\n",
            "spark-sql-api_2.12-3.5.0.jar\n",
            "spark-streaming_2.12-3.5.0.jar\n",
            "spark-tags_2.12-3.5.0.jar\n",
            "spark-unsafe_2.12-3.5.0.jar\n",
            "spark-yarn_2.12-3.5.0.jar\n",
            "spire_2.12-0.17.0.jar\n",
            "spire-macros_2.12-0.17.0.jar\n",
            "spire-platform_2.12-0.17.0.jar\n",
            "spire-util_2.12-0.17.0.jar\n",
            "ST4-4.0.4.jar\n",
            "stax-api-1.0.1.jar\n",
            "stream-2.9.6.jar\n",
            "super-csv-2.2.0.jar\n",
            "threeten-extra-1.7.1.jar\n",
            "tink-1.9.0.jar\n",
            "transaction-api-1.1.jar\n",
            "univocity-parsers-2.9.1.jar\n",
            "xbean-asm9-shaded-4.23.jar\n",
            "xz-1.9.jar\n",
            "zjsonpatch-0.3.0.jar\n",
            "zookeeper-3.6.3.jar\n",
            "zookeeper-jute-3.6.3.jar\n",
            "zstd-jni-1.5.5-4.jar\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/lib/python3.10/dist-packages/pyspark/jars/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-cS61ZRVugj"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .config(\"spark.jars\", \"/usr/local/lib/python3.9/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.3.2-s_2.11.jar\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)  # Property used to format output tables better\\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8eDzN3UHSKA"
      },
      "source": [
        "# Dataset_location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx6NyV8wE8_9"
      },
      "outputs": [],
      "source": [
        "input_dataset_path = '/content/sample_data/soc-Epinions1.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "UBoYooF9RN-X",
        "outputId": "6bf01ad9-480a-4a5f-e1d7-3d56598231fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+----------+--------+\n",
              "|FromNodeId|ToNodeId|\n",
              "+----------+--------+\n",
              "|         0|       4|\n",
              "|         0|       5|\n",
              "|         0|       7|\n",
              "|         0|       8|\n",
              "|         0|       9|\n",
              "|         0|      10|\n",
              "|         0|      11|\n",
              "|         0|      12|\n",
              "|         0|      13|\n",
              "|         0|      14|\n",
              "|         0|      15|\n",
              "|         0|      16|\n",
              "|         0|      17|\n",
              "|         0|      18|\n",
              "|         0|      19|\n",
              "|         0|      20|\n",
              "|         0|      21|\n",
              "|         0|      22|\n",
              "|         0|      23|\n",
              "|         0|      24|\n",
              "+----------+--------+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>FromNodeId</th><th>ToNodeId</th></tr>\n",
              "<tr><td>0</td><td>4</td></tr>\n",
              "<tr><td>0</td><td>5</td></tr>\n",
              "<tr><td>0</td><td>7</td></tr>\n",
              "<tr><td>0</td><td>8</td></tr>\n",
              "<tr><td>0</td><td>9</td></tr>\n",
              "<tr><td>0</td><td>10</td></tr>\n",
              "<tr><td>0</td><td>11</td></tr>\n",
              "<tr><td>0</td><td>12</td></tr>\n",
              "<tr><td>0</td><td>13</td></tr>\n",
              "<tr><td>0</td><td>14</td></tr>\n",
              "<tr><td>0</td><td>15</td></tr>\n",
              "<tr><td>0</td><td>16</td></tr>\n",
              "<tr><td>0</td><td>17</td></tr>\n",
              "<tr><td>0</td><td>18</td></tr>\n",
              "<tr><td>0</td><td>19</td></tr>\n",
              "<tr><td>0</td><td>20</td></tr>\n",
              "<tr><td>0</td><td>21</td></tr>\n",
              "<tr><td>0</td><td>22</td></tr>\n",
              "<tr><td>0</td><td>23</td></tr>\n",
              "<tr><td>0</td><td>24</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType\n",
        "\n",
        "edge_schema = StructType([\n",
        "    StructField(\"FromNodeId\", IntegerType(), True),\n",
        "    StructField(\"ToNodeId\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "edges = spark.read.csv(input_dataset_path, sep='\\t', schema=edge_schema, header=True)\n",
        "edges = edges.rdd.zipWithIndex().filter(lambda x: x[1] >= 3).map(lambda x: x[0]).toDF()\n",
        "edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW3Z95hFRWLe",
        "outputId": "2038027d-ec5d-44c5-8c0f-06dc0a46059e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|   id|\n",
            "+-----+\n",
            "|   26|\n",
            "|   29|\n",
            "| 2040|\n",
            "| 2250|\n",
            "| 2453|\n",
            "| 2509|\n",
            "| 2927|\n",
            "|  964|\n",
            "|22129|\n",
            "| 1677|\n",
            "| 5385|\n",
            "| 1950|\n",
            "| 6721|\n",
            "| 1806|\n",
            "| 7225|\n",
            "|50124|\n",
            "| 4894|\n",
            "| 1697|\n",
            "| 8440|\n",
            "| 7747|\n",
            "+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, concat_ws\n",
        "\n",
        "vertex_schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "src_vertices = edges.select(col(\"FromNodeId\").alias(\"id\"))\n",
        "dst_vertices = edges.select(col(\"ToNodeId\").alias(\"id\"))\n",
        "\n",
        "vertices = src_vertices.union(dst_vertices).distinct()\n",
        "\n",
        "vertices = vertices.select('id').distinct()\n",
        "vertices = vertices.selectExpr(\"id as id\")\n",
        "vertices = vertices.selectExpr(\"cast(id as int) as id\")\n",
        "\n",
        "vertices.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26ztb-kLV5Hi"
      },
      "outputs": [],
      "source": [
        "from graphframes import *\n",
        "from graphframes import GraphFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMiwxTujWKtM",
        "outputId": "3a112871-b164-4039-87a8-8ba7aaba94dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Version :3.5.0\n",
            "PySpark Version :3.5.0\n"
          ]
        }
      ],
      "source": [
        "print('PySpark Version :'+spark.version)\n",
        "print('PySpark Version :'+spark.sparkContext.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTkOL-3XWNBd"
      },
      "outputs": [],
      "source": [
        "# Rename columns in edges DataFrame to match the expected schema.\n",
        "edges = edges.withColumnRenamed('FromNodeId', 'src').withColumnRenamed('ToNodeId', 'dst')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "LXTRPvfvWPId",
        "outputId": "b3116df5-c9b9-43b0-efcb-08c7e3635dfd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----+\n",
              "|   id|\n",
              "+-----+\n",
              "|   26|\n",
              "|   29|\n",
              "| 2040|\n",
              "| 2250|\n",
              "| 2453|\n",
              "| 2509|\n",
              "| 2927|\n",
              "|  964|\n",
              "|22129|\n",
              "| 1677|\n",
              "| 5385|\n",
              "| 1950|\n",
              "| 6721|\n",
              "| 1806|\n",
              "| 7225|\n",
              "|50124|\n",
              "| 4894|\n",
              "| 1697|\n",
              "| 8440|\n",
              "| 7747|\n",
              "+-----+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>id</th></tr>\n",
              "<tr><td>26</td></tr>\n",
              "<tr><td>29</td></tr>\n",
              "<tr><td>2040</td></tr>\n",
              "<tr><td>2250</td></tr>\n",
              "<tr><td>2453</td></tr>\n",
              "<tr><td>2509</td></tr>\n",
              "<tr><td>2927</td></tr>\n",
              "<tr><td>964</td></tr>\n",
              "<tr><td>22129</td></tr>\n",
              "<tr><td>1677</td></tr>\n",
              "<tr><td>5385</td></tr>\n",
              "<tr><td>1950</td></tr>\n",
              "<tr><td>6721</td></tr>\n",
              "<tr><td>1806</td></tr>\n",
              "<tr><td>7225</td></tr>\n",
              "<tr><td>50124</td></tr>\n",
              "<tr><td>4894</td></tr>\n",
              "<tr><td>1697</td></tr>\n",
              "<tr><td>8440</td></tr>\n",
              "<tr><td>7747</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "display(vertices)\n",
        "type(vertices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iqt5kFBWRVf",
        "outputId": "33057c47-cf53-4167-9140-8b0f05e7c4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "g = GraphFrame(vertices, edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AoYtpZXWUXs",
        "outputId": "f3c9696c-b430-4c74-f260-7d1fcec5f309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+\n",
            "|   id|outDegree|\n",
            "+-----+---------+\n",
            "|   26|      197|\n",
            "|   29|      125|\n",
            "| 2040|      120|\n",
            "| 2250|       36|\n",
            "| 2453|       45|\n",
            "| 2509|      189|\n",
            "| 2927|       16|\n",
            "|  964|       54|\n",
            "|22129|        6|\n",
            "| 1677|      206|\n",
            "| 5385|       42|\n",
            "| 1950|        4|\n",
            "| 6721|       10|\n",
            "| 1806|       70|\n",
            "| 7225|        2|\n",
            "|50124|        2|\n",
            "| 4894|       21|\n",
            "| 1697|       30|\n",
            "| 8440|        6|\n",
            "| 7747|        5|\n",
            "+-----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "g.outDegrees.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yal7XcNOWiWh",
        "outputId": "65cf9654-9eee-48d8-c49c-4fe01c133253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|   id|inDegree|\n",
            "+-----+--------+\n",
            "|   26|     226|\n",
            "|   29|     369|\n",
            "| 2040|     154|\n",
            "| 2250|      38|\n",
            "| 2453|      37|\n",
            "| 2509|      60|\n",
            "| 2927|      14|\n",
            "|  964|      13|\n",
            "|22129|       7|\n",
            "| 1677|      65|\n",
            "| 5385|      21|\n",
            "| 1950|      20|\n",
            "| 6721|       8|\n",
            "| 1806|      74|\n",
            "| 7747|       5|\n",
            "| 9458|      24|\n",
            "| 2529|      10|\n",
            "| 2214|      21|\n",
            "| 7279|       1|\n",
            "|11945|       9|\n",
            "+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "g.inDegrees.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKqWjm2zXJUs"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import asc, desc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4MwEqBYGNVa"
      },
      "source": [
        "## A. Find the top 5 nodes with the highest outdegree and find the count of the number of outgoing edges in each\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Io7l2CeW9yv",
        "outputId": "f3026594-b51e-4e9c-8538-903e1160247f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+\n",
            "|   id|outDegree|\n",
            "+-----+---------+\n",
            "|  645|     1801|\n",
            "|  763|     1669|\n",
            "|  634|     1621|\n",
            "|71399|     1128|\n",
            "| 3924|      976|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "out_degree = g.outDegrees.orderBy(desc(\"OutDegree\")).limit(5)\n",
        "out_degree.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZb_p6x-GUVH"
      },
      "source": [
        "## B.  Find the top 5 nodes with the highest indegree and find the count of the number of incoming edges in each\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRO8dTmDXKbF",
        "outputId": "7227e65b-a486-47bb-978d-f1f71b5995d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|inDegree|\n",
            "+---+--------+\n",
            "| 18|    3035|\n",
            "|143|    1521|\n",
            "|737|    1317|\n",
            "|790|    1284|\n",
            "|136|    1180|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "in_degree = g.inDegrees.orderBy(desc(\"inDegree\")).limit(5)\n",
        "in_degree.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0SjueaXXjfB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay-b303xGXVl"
      },
      "source": [
        "## C. Calculate PageRank for each of the nodes and output the top 5 nodes with the highest PageRank values. You are free to define any suitable parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKjka-OBXSUt",
        "outputId": "cbae9b51-36b5-4789-d15a-cefadd9bb26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+\n",
            "|  id|          pagerank|\n",
            "+----+------------------+\n",
            "|  18|337.43855026548573|\n",
            "| 737|234.39478550925054|\n",
            "| 118|157.84625437275847|\n",
            "|1719|154.72317556830524|\n",
            "| 136|147.77563262328627|\n",
            "+----+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pagerank = g.pageRank(resetProbability=0.15, tol=0.01).vertices\n",
        "top_pagerank = pagerank.sort(col(\"pagerank\").desc()).limit(5)\n",
        "top_pagerank.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_02ZN8IG0q6"
      },
      "source": [
        "## D. Run the connected components algorithm on it and the top 5 components with the largest number of nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uNXwAnqXfLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257cc6a5-7795-4011-95d0-c0b97c419de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|component|count|\n",
            "+---------+-----+\n",
            "|        0|75877|\n",
            "|    71749|    2|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sc = spark.sparkContext\n",
        "sc.setCheckpointDir(\"/tmp\")\n",
        "\n",
        "connected_components = g.connectedComponents()\n",
        "\n",
        "component_sizes = connected_components.groupBy(\"component\").count()\n",
        "\n",
        "sorted_components = component_sizes.sort(col(\"count\").desc())\n",
        "\n",
        "top_components = sorted_components.limit(5)\n",
        "top_components.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T0p0LJ9G6Pe"
      },
      "source": [
        "## E. Run the triangle counts algorithm on each of the vertices and output the top 5 vertices with the largest triangle count. In case of ties, you can randomly select the top 5 vertices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "454KnSblX3y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82088e22-ab00-4906-8057-14dcde98c9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id|count|\n",
            "+---+-----+\n",
            "|645|48674|\n",
            "| 18|47203|\n",
            "| 27|25817|\n",
            "|634|25230|\n",
            "| 44|24752|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = g.triangleCount()\n",
        "\n",
        "sorted_results = results.select(\"id\", \"count\").sort(col(\"count\").desc())\n",
        "\n",
        "top_vertices = sorted_results.limit(5)\n",
        "top_vertices.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing output to specified file"
      ],
      "metadata": {
        "id": "HMqwU9r8v1H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = 'combined_output.txt'"
      ],
      "metadata": {
        "id": "wpetEWfoxXhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_file_path, 'w') as file:\n",
        "    file.write(\"Top 5 nodes with highest outdegree:\\n\")\n",
        "    file.write(out_degree.toPandas().to_string(index=False))\n",
        "    file.write(\"\\n\\n\")\n",
        "\n",
        "    file.write(\"Top 5 nodes with highest indegree:\\n\")\n",
        "    file.write(in_degree.toPandas().to_string(index=False))\n",
        "    file.write(\"\\n\\n\")\n",
        "\n",
        "    file.write(\"Top 5 nodes with highest PageRank values:\\n\")\n",
        "    file.write(top_pagerank.toPandas().to_string(index=False))\n",
        "    file.write(\"\\n\\n\")\n",
        "\n",
        "    file.write(\"Top 5 components with largest number of nodes:\\n\")\n",
        "    file.write(top_components.toPandas().to_string(index=False))\n",
        "    file.write(\"\\n\\n\")\n",
        "\n",
        "    file.write(\"Top 5 vertices with largest triangle count:\\n\")\n",
        "    file.write(top_vertices.toPandas().to_string(index=False))\n",
        "    file.write(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "FFAXYCoF1wzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}